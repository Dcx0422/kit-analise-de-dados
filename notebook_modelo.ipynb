{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NOME DO PROJETO] - Análise Exploratória de Dados\n",
    "\n",
    "**Objetivo:** Descreva aqui o objetivo principal desta análise.\n",
    "\n",
    "**Fonte dos Dados:** Indique a origem dos dados (ex: Sistema de Vendas, Relatório de Marketing, etc.).\n",
    "\n",
    "**Data:** 17 de agosto de 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração do Ambiente\n",
    "\n",
    "Nesta seção, importamos as bibliotecas e configuramos o ambiente para uma melhor visualização dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas de manipulação de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Bibliotecas de visualização\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Kit do Analista\n",
    "from ferramentas_analista import carregar_dados, converter_notebook_para_py\n",
    "\n",
    "# --- Configurações de Visualização ---\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None) # Descomente se precisar ver todas as linhas\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Ambiente configurado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de Dados\n",
    "\n",
    "Utilizamos a função `carregar_dados` para importar os dados de forma inteligente (CSV, Excel, JSON, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_arquivo_dados = 'caminho/para/seu/arquivo.csv'\n",
    "df = carregar_dados(caminho_arquivo_dados)\n",
    "\n",
    "if df is not None:\n",
    "    df_analise = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspeção Inicial dos Dados (Dossiê do Dataset)\n",
    "\n",
    "Esta é a etapa mais crucial para 'sentir' os dados. Realizamos uma série de verificações básicas para criar um dossiê completo sobre o dataset que recebemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_analise' in locals() and df_analise is not None:\n",
    "    print(f\"O dataset contém {df_analise.shape[0]} linhas e {df_analise.shape[1]} colunas.\\n\")\n",
    "    \n",
    "    print(\"--- 1. Visualização das Primeiras e Últimas Linhas ---\")\n",
    "    display(df_analise.head())\n",
    "    display(df_analise.tail())\n",
    "\n",
    "    print(\"\\n--- 2. Nomes de Todas as Colunas ---\")\n",
    "    print(df_analise.columns.tolist())\n",
    "    \n",
    "    print(\"\\n--- 3. Tipos de Dados e Uso de Memória ---\")\n",
    "    df_analise.info(memory_usage='deep')\n",
    "    \n",
    "    print(\"\\n--- 4. Análise de Linhas Duplicadas (em colunas seguras) ---\")\n",
    "    colunas_problematicas = []\n",
    "    for col in df_analise.columns:\n",
    "        if df_analise[col].apply(lambda x: isinstance(x, (list, dict))).any():\n",
    "            colunas_problematicas.append(col)\n",
    "    \n",
    "    if colunas_problematicas:\n",
    "        print(f\"Aviso: As seguintes colunas contêm listas/dicionários e serão ignoradas na checagem: {colunas_problematicas}\")\n",
    "    \n",
    "    colunas_para_verificar = [col for col in df_analise.columns if col not in colunas_problematicas]\n",
    "    num_duplicatas = df_analise.duplicated(subset=colunas_para_verificar).sum()\n",
    "    \n",
    "    if num_duplicatas > 0:\n",
    "        print(f\"\\033[91mAVISO: Foram encontradas {num_duplicatas} linhas duplicadas.\\033[0m\")\n",
    "    else:\n",
    "        print(\"✅ Nenhuma linha duplicada encontrada.\")\n",
    "        \n",
    "    print(\"\\n--- 5. Análise de Valores Únicos (Cardinalidade) ---\")\n",
    "    print(\"Contagem de valores únicos por coluna (ajuda a identificar IDs e constantes):\")\n",
    "    display(df_analise[colunas_para_verificar].nunique().sort_values(ascending=True).to_frame(name='Contagem de Únicos'))\n",
    "    \n",
    "    print(\"\\n--- 6. Análise de Valores Nulos (Percentual) ---\")\n",
    "    percent_nulos = (df_analise.isnull().sum() / len(df_analise) * 100).sort_values(ascending=False)\n",
    "    percent_nulos = percent_nulos[percent_nulos > 0]\n",
    "    if not percent_nulos.empty:\n",
    "        print(\"Colunas com valores nulos:\")\n",
    "        display(percent_nulos.to_frame(name='Percentual de Nulos (%)'))\n",
    "    else:\n",
    "        print(\"✅ Nenhuma coluna com valores nulos encontrada.\")\n",
    "        \n",
    "    print(\"\\n--- 7. Estatísticas Descritivas (Colunas Numéricas) ---\")\n",
    "    display(df_analise.describe())\n",
    "    \n",
    "    print(\"\\n--- 8. Estatísticas Descritivas (Colunas Categóricas) ---\")\n",
    "    display(df_analise.describe(include=['object', 'category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Limpeza e Pré-Processamento (Checklist de ETL)\n",
    "\n",
    "Com base no dossiê acima, tratamos os problemas identificados. Descomente e adapte os blocos de código que forem relevantes para o seu projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.1 Seleção e Remoção de Colunas ---\n",
    "# # Opção A: Remover colunas irrelevantes pelo nome\n",
    "# colunas_para_remover = ['id_transacao', 'coluna_inutil']\n",
    "# df_analise.drop(columns=colunas_para_remover, inplace=True, errors='ignore')\n",
    "\n",
    "# # Opção B: Selecionar apenas as colunas que você quer manter\n",
    "# colunas_para_manter = ['id_cliente', 'data_venda', 'produto', 'preco']\n",
    "# df_analise = df_analise[colunas_para_manter]\n",
    "\n",
    "# # Opção C (Avançado): Usar .filter() para selecionar colunas por padrão no nome\n",
    "# df_ids = df_analise.filter(like='id') # Pega todas as colunas que contêm 'id' no nome\n",
    "\n",
    "# --- 4.2 Renomeação de Colunas ---\n",
    "# # Renomear colunas específicas para nomes mais claros e sem acentos/espaços\n",
    "# df_analise.rename(columns={'NM_CLIENTE': 'nome_cliente', 'DT_VENDA': 'data_venda'}, inplace=True)\n",
    "\n",
    "# # Padronizar todos os nomes de colunas (ex: para minúsculas e snake_case)\n",
    "# df_analise.columns = df_analise.columns.str.strip().str.lower().str.replace(' ', '_', regex=False).str.replace('(', '', regex=False).str.replace(')', '', regex=False)\n",
    "\n",
    "# --- 4.3 Tratamento de Dados Ausentes ---\n",
    "# # Estratégia 1: Remover linhas onde colunas CRÍTICAS são nulas\n",
    "# df_analise.dropna(subset=['id_cliente', 'valor_compra'], inplace=True)\n",
    "\n",
    "# # Estratégia 2: Preencher nulos com um valor específico (medidas de tendência central ou constantes)\n",
    "# df_analise['idade'].fillna(df_analise['idade'].median(), inplace=True)\n",
    "# df_analise['categoria_produto'].fillna('Desconhecida', inplace=True)\n",
    "\n",
    "# --- 4.4 Correção de Tipos de Dados ---\n",
    "# # Converter colunas de data que foram lidas como texto\n",
    "# df_analise['data_venda'] = pd.to_datetime(df_analise['data_venda'], errors='coerce') # 'coerce' transforma datas inválidas em NaT (Not a Time)\n",
    "\n",
    "# # Exemplo prático: Converter uma coluna de preço (ex: 'R$ 1.234,56') para número\n",
    "# if 'preco' in df_analise.columns and df_analise['preco'].dtype == 'object':\n",
    "#     df_analise['preco'] = df_analise['preco'].str.replace('R$', '', regex=False).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).astype(float)\n",
    "\n",
    "# # Converter para tipos de dados que economizam memória\n",
    "# df_analise['status'] = df_analise['status'].astype('category')\n",
    "\n",
    "# --- 4.5 Tratamento de Duplicatas ---\n",
    "# # Remover linhas que são inteiramente duplicadas (usando o subset seguro definido na inspeção)\n",
    "# df_analise.drop_duplicates(subset=colunas_para_verificar, inplace=True)\n",
    "\n",
    "# --- 4.6 Criação de Novas Colunas (Engenharia de Features) ---\n",
    "# # Extrair informações de datas\n",
    "# if 'data_venda' in df_analise.columns:\n",
    "#     df_analise['ano_venda'] = df_analise['data_venda'].dt.year\n",
    "#     df_analise['mes_venda'] = df_analise['data_venda'].dt.month\n",
    "\n",
    "# # Criar categorias a partir de uma variável numérica (Binning)\n",
    "# df_analise['faixa_etaria'] = pd.cut(df_analise['idade'], bins=[0, 18, 35, 60, 100], labels=['Jovem', 'Adulto', 'Meia-Idade', 'Idoso'])\n",
    "\n",
    "# --- 4.7 Limpeza e Padronização de Strings ---\n",
    "# # Remover espaços em branco no início e no fim de uma coluna de texto\n",
    "# df_analise['nome_produto'] = df_analise['nome_produto'].str.strip()\n",
    "\n",
    "# # Padronizar para letras minúsculas\n",
    "# df_analise['cidade'] = df_analise['cidade'].str.lower()\n",
    "\n",
    "print(\"Etapa de limpeza e pré-processamento concluída. Verifique os resultados abaixo.\")\n",
    "# df_analise.info() # É uma boa prática verificar os tipos de dados novamente após a limpeza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transformação e Agrupamento de Dados\n",
    "\n",
    "Após a limpeza, podemos começar a transformar os dados, criando agregações e juntando informações de diferentes fontes para responder perguntas de negócio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.1 Agrupamentos com .groupby() ---\n",
    "# # Objetivo: Calcular estatísticas agregadas para diferentes categorias.\n",
    "# # Exemplo: Calcular o preço médio, mínimo e máximo por categoria de produto.\n",
    "# df_agrupado_categoria = df_analise.groupby('categoria_produto').agg(\n",
    "#     preco_medio=('preco', 'mean'),\n",
    "#     preco_maximo=('preco', 'max'),\n",
    "#     contagem=('produto', 'count')\n",
    "# ).sort_values(by='preco_medio', ascending=False)\n",
    "# \n",
    "# display(df_agrupado_categoria)\n",
    "\n",
    "# --- 5.2 Tabelas Dinâmicas com .pivot_table() ---\n",
    "# # Objetivo: Reorganizar os dados em formato de matriz, similar a uma tabela dinâmica do Excel.\n",
    "# # Exemplo: Ver o faturamento total por `ano` e `mes`.\n",
    "# df_pivot = pd.pivot_table(\n",
    "#     df_analise,\n",
    "#     values='faturamento',\n",
    "#     index='ano_venda',\n",
    "#     columns='mes_venda',\n",
    "#     aggfunc='sum',\n",
    "#     fill_value=0 # Preenche meses sem vendas com 0\n",
    "# )\n",
    "# \n",
    "# display(df_pivot)\n",
    "\n",
    "# --- 5.3 Combinação de Datasets com .merge() ---\n",
    "# # Objetivo: Enriquecer o dataset principal com informações de outras tabelas.\n",
    "# # Exemplo: Juntar os dados de vendas (df_analise) com um DataFrame de informações de clientes (df_clientes).\n",
    "\n",
    "# # Criando um DataFrame de exemplo para clientes\n",
    "# dados_clientes = {'id_cliente': [101, 102, 103], 'regiao_cliente': ['Sudeste', 'Nordeste', 'Sudeste']}\n",
    "# df_clientes = pd.DataFrame(dados_clientes)\n",
    "\n",
    "# # Juntando os dois DataFrames pela coluna em comum ('id_cliente')\n",
    "# df_completo = pd.merge(\n",
    "#     df_analise, \n",
    "#     df_clientes, \n",
    "#     on='id_cliente', # Chave para a junção\n",
    "#     how='left'      # Mantém todos os registros de vendas, mesmo que não encontre cliente correspondente\n",
    "# )\n",
    "# \n",
    "# display(df_completo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exportação dos Dados Tratados\n",
    "\n",
    "Após a limpeza e transformação, é uma excelente prática salvar o DataFrame resultante. Isso cria um \"checkpoint\" de dados limpos que pode ser usado em outras análises, relatórios ou modelos, sem precisar repetir todo o processo de ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Salvando em CSV (.to_csv) ---\n",
    "# # SUGESTÃO: Use ';' como separador e encoding 'utf-8-sig' para máxima compatibilidade com Excel.\n",
    "# caminho_saida_csv = 'dados_analise_limpos.csv'\n",
    "# df_analise.to_csv(\n",
    "#     caminho_saida_csv,\n",
    "#     index=False,          # Para não salvar o índice do DataFrame como uma coluna no arquivo\n",
    "#     sep=';',              # Ponto e vírgula é bem reconhecido pelo Excel no Brasil\n",
    "#     decimal=',',          # Define a vírgula como separador decimal\n",
    "#     encoding='utf-8-sig'  # 'sig' (Byte Order Mark) ajuda o Excel a reconhecer a codificação UTF-8\n",
    "# )\n",
    "# print(f\"DataFrame limpo salvo em '{caminho_saida_csv}'\")\n",
    "\n",
    "# --- Salvando em Excel (.to_excel) ---\n",
    "# # Útil para compartilhar com áreas de negócio que não usam Python.\n",
    "# caminho_saida_excel = 'dados_analise_limpos.xlsx'\n",
    "# df_analise.to_excel(\n",
    "#     caminho_saida_excel,\n",
    "#     index=False,\n",
    "#     sheet_name='Dados Principais'\n",
    "# )\n",
    "# print(f\"DataFrame limpo salvo em '{caminho_saida_excel}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análise Exploratória de Dados (EDA)\n",
    "\n",
    "Com os dados limpos, investigamos e visualizamos os dados para encontrar padrões e insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Análise Univariada\n",
    "Análise de cada variável individualmente para entender sua distribuição e características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Para variáveis NUMÉRICAS --- \n",
    "# SUGESTÃO: Use Histogramas para ver a distribuição e Boxplots para identificar outliers.\n",
    "\n",
    "# Exemplo com Plotly (interativo)\n",
    "# coluna_numerica = 'sua_coluna_numerica'\n",
    "# fig = px.histogram(df_analise, x=coluna_numerica, title=f'Distribuição de {coluna_numerica}', nbins=50, marginal='box')\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Para variáveis CATEGÓRICAS ---\n",
    "# SUGESTÃO: Use Gráficos de Barras para ver a frequência de cada categoria.\n",
    "\n",
    "# Exemplo com Plotly (interativo)\n",
    "# coluna_categorica = 'sua_coluna_categorica'\n",
    "# contagem = df_analise[coluna_categorica].value_counts().reset_index()\n",
    "# contagem.columns = [coluna_categorica, 'contagem']\n",
    "# fig = px.bar(contagem, y=coluna_categorica, x='contagem', title=f'Contagem por {coluna_categorica}', orientation='h', text='contagem')\n",
    "# fig.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Análise Bivariada\n",
    "Análise da relação entre pares de variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Relação entre duas variáveis NUMÉRICAS ---\n",
    "# SUGESTÃO: Use Gráfico de Dispersão (Scatter Plot) para identificar correlações.\n",
    "\n",
    "# Exemplo com Plotly (interativo)\n",
    "# fig = px.scatter(df_analise, x='coluna_numerica_X', y='coluna_numerica_Y', \n",
    "#                  title='Relação entre X e Y', \n",
    "#                  hover_data=['outra_coluna_para_tooltip'], # Adiciona mais infos ao passar o mouse\n",
    "#                  trendline='ols') # Adiciona uma linha de tendência\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Relação entre uma variável NUMÉRICA e uma CATEGÓRICA ---\n",
    "# SUGESTÃO: Use Boxplots ou Violin Plots para comparar a distribuição da variável numérica entre as categorias.\n",
    "\n",
    "# Exemplo com Plotly (interativo)\n",
    "# fig = px.box(df_analise, x='coluna_categorica', y='coluna_numerica', \n",
    "#              title='Distribuição Numérica por Categoria', \n",
    "#              points='all') # Mostra todos os pontos de dados\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Análise Multivariada\n",
    "Análise da relação entre três ou mais variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUGESTÃO: Use Gráfico de Dispersão com atributos de cor ou tamanho para adicionar uma terceira dimensão.\n",
    "\n",
    "# Exemplo com Plotly (interativo)\n",
    "# fig = px.scatter(df_analise, x='coluna_numerica_X', y='coluna_numerica_Y', \n",
    "#                  color='coluna_categorica',  # Terceira dimensão (categórica) por cor\n",
    "#                  size='outra_coluna_numerica', # Quarta dimensão (numérica) por tamanho da bolha\n",
    "#                  title='Análise Multivariada')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusões e Próximos Passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Escreva aqui os principais insights e próximos passos da análise.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exportação do Script\n",
    "\n",
    "Convertemos este notebook em um script Python limpo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certifique-se de que o nome do arquivo corresponde ao seu notebook\n",
    "converter_notebook_para_py('notebook_modelo.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}