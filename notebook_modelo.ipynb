{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NOME DO PROJETO] - An√°lise Explorat√≥ria de Dados\n",
    "\n",
    "**Objetivo:** Descreva aqui o objetivo principal desta an√°lise.\n",
    "\n",
    "**Fonte dos Dados:** Indique a origem dos dados (ex: Sistema de Vendas, Relat√≥rio de Marketing, etc.).\n",
    "\n",
    "**Data:** 17 de agosto de 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o do Ambiente\n",
    "\n",
    "Nesta se√ß√£o, importamos as bibliotecas e configuramos o ambiente para uma melhor visualiza√ß√£o dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente configurado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Importa√ß√£o de bibliotecas essenciais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importa√ß√£o das nossas ferramentas\n",
    "from ferramentas_analista import carregar_dados, converter_notebook_para_py\n",
    "\n",
    "# --- Configura√ß√µes de Visualiza√ß√£o (Essencial para An√°lise) ---\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None) # Descomente se precisar ver todas as linhas\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# Configura√ß√µes de gr√°ficos\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Ambiente configurado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de Dados\n",
    "\n",
    "Utilizamos a fun√ß√£o `carregar_dados` para importar os dados de forma inteligente (CSV, Excel, JSON, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üïµÔ∏è‚Äç‚ôÇÔ∏è Analisando e Carregando: iris.csv ---\n",
      "‚ùå ERRO: Arquivo n√£o encontrado em 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv'\n"
     ]
    }
   ],
   "source": [
    "caminho_arquivo_dados = 'iris.csv'\n",
    "df = carregar_dados(caminho_arquivo_dados)\n",
    "\n",
    "if df is not None:\n",
    "    df_analise = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspe√ß√£o Inicial dos Dados (Dossi√™ do Dataset)\n",
    "\n",
    "Esta √© a etapa mais crucial para 'sentir' os dados. Realizamos uma s√©rie de verifica√ß√µes b√°sicas para criar um dossi√™ completo sobre o dataset que recebemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_analise' in locals() and df_analise is not None:\n",
    "    print(f\"O dataset cont√©m {df_analise.shape[0]} linhas e {df_analise.shape[1]} colunas.\\n\")\n",
    "    \n",
    "    print(\"--- 1. Visualiza√ß√£o das Primeiras e √öltimas Linhas ---\")\n",
    "    display(df_analise.head())\n",
    "    display(df_analise.tail())\n",
    "\n",
    "    print(\"\\n--- 2. Nomes de Todas as Colunas ---\")\n",
    "    print(df_analise.columns.tolist())\n",
    "    \n",
    "    print(\"\\n--- 3. Tipos de Dados e Uso de Mem√≥ria ---\")\n",
    "    df_analise.info(memory_usage='deep')\n",
    "    \n",
    "    print(\"\\n--- 4. An√°lise de Linhas Duplicadas (em colunas seguras) ---\")\n",
    "    colunas_problematicas = []\n",
    "    for col in df_analise.columns:\n",
    "        if df_analise[col].apply(lambda x: isinstance(x, (list, dict))).any():\n",
    "            colunas_problematicas.append(col)\n",
    "    \n",
    "    if colunas_problematicas:\n",
    "        print(f\"Aviso: As seguintes colunas cont√™m listas/dicion√°rios e ser√£o ignoradas na checagem: {colunas_problematicas}\")\n",
    "    \n",
    "    colunas_para_verificar = [col for col in df_analise.columns if col not in colunas_problematicas]\n",
    "    num_duplicatas = df_analise.duplicated(subset=colunas_para_verificar).sum()\n",
    "    \n",
    "    if num_duplicatas > 0:\n",
    "        print(f\"\\033[91mAVISO: Foram encontradas {num_duplicatas} linhas duplicadas.\\033[0m\")\n",
    "    else:\n",
    "        print(\"‚úÖ Nenhuma linha duplicada encontrada.\")\n",
    "        \n",
    "    print(\"\\n--- 5. An√°lise de Valores √önicos (Cardinalidade) ---\")\n",
    "    print(\"Contagem de valores √∫nicos por coluna (ajuda a identificar IDs e constantes):\")\n",
    "    display(df_analise[colunas_para_verificar].nunique().sort_values(ascending=True).to_frame(name='Contagem de √önicos'))\n",
    "    \n",
    "    print(\"\\n--- 6. An√°lise de Valores Nulos (Percentual) ---\")\n",
    "    percent_nulos = (df_analise.isnull().sum() / len(df_analise) * 100).sort_values(ascending=False)\n",
    "    percent_nulos = percent_nulos[percent_nulos > 0]\n",
    "    if not percent_nulos.empty:\n",
    "        print(\"Colunas com valores nulos:\")\n",
    "        display(percent_nulos.to_frame(name='Percentual de Nulos (%)'))\n",
    "    else:\n",
    "        print(\"‚úÖ Nenhuma coluna com valores nulos encontrada.\")\n",
    "        \n",
    "    print(\"\\n--- 7. Estat√≠sticas Descritivas (Colunas Num√©ricas) ---\")\n",
    "    display(df_analise.describe())\n",
    "    \n",
    "    print(\"\\n--- 8. Estat√≠sticas Descritivas (Colunas Categ√≥ricas) ---\")\n",
    "    display(df_analise.describe(include=['object', 'category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Limpeza e Pr√©-Processamento (Checklist de ETL)\n",
    "\n",
    "Com base no dossi√™ acima, tratamos os problemas identificados. Descomente e adapte os blocos de c√≥digo que forem relevantes para o seu projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.1 Sele√ß√£o e Remo√ß√£o de Colunas ---\n",
    "# # Op√ß√£o A: Remover colunas irrelevantes pelo nome\n",
    "# colunas_para_remover = ['id_transacao', 'coluna_inutil']\n",
    "# df_analise.drop(columns=colunas_para_remover, inplace=True, errors='ignore')\n",
    "\n",
    "# # Op√ß√£o B: Selecionar apenas as colunas que voc√™ quer manter\n",
    "# colunas_para_manter = ['id_cliente', 'data_venda', 'produto', 'preco']\n",
    "# df_analise = df_analise[colunas_para_manter]\n",
    "\n",
    "# # Op√ß√£o C (Avan√ßado): Usar .filter() para selecionar colunas por padr√£o no nome\n",
    "# df_ids = df_analise.filter(like='id') # Pega todas as colunas que cont√™m 'id' no nome\n",
    "\n",
    "# --- 4.2 Renomea√ß√£o de Colunas ---\n",
    "# # Renomear colunas espec√≠ficas para nomes mais claros e sem acentos/espa√ßos\n",
    "# df_analise.rename(columns={'NM_CLIENTE': 'nome_cliente', 'DT_VENDA': 'data_venda'}, inplace=True)\n",
    "\n",
    "# # Padronizar todos os nomes de colunas (ex: para min√∫sculas e snake_case)\n",
    "# df_analise.columns = df_analise.columns.str.strip().str.lower().str.replace(' ', '_', regex=False).str.replace('(', '', regex=False).str.replace(')', '', regex=False)\n",
    "\n",
    "# --- 4.3 Tratamento de Dados Ausentes ---\n",
    "# # Estrat√©gia 1: Remover linhas onde colunas CR√çTICAS s√£o nulas\n",
    "# df_analise.dropna(subset=['id_cliente', 'valor_compra'], inplace=True)\n",
    "\n",
    "# # Estrat√©gia 2: Preencher nulos com um valor espec√≠fico (medidas de tend√™ncia central ou constantes)\n",
    "# df_analise['idade'].fillna(df_analise['idade'].median(), inplace=True)\n",
    "# df_analise['categoria_produto'].fillna('Desconhecida', inplace=True)\n",
    "\n",
    "# --- 4.4 Corre√ß√£o de Tipos de Dados ---\n",
    "# # Converter colunas de data que foram lidas como texto\n",
    "# df_analise['data_venda'] = pd.to_datetime(df_analise['data_venda'], errors='coerce') # 'coerce' transforma datas inv√°lidas em NaT (Not a Time)\n",
    "\n",
    "# # Exemplo pr√°tico: Converter uma coluna de pre√ßo (ex: 'R$ 1.234,56') para n√∫mero\n",
    "# if df_analise['preco'].dtype == 'object':\n",
    "#     df_analise['preco'] = df_analise['preco'].str.replace('R$', '', regex=False).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).astype(float)\n",
    "\n",
    "# # Converter para tipos de dados que economizam mem√≥ria\n",
    "# df_analise['status'] = df_analise['status'].astype('category')\n",
    "\n",
    "# --- 4.5 Tratamento de Duplicatas ---\n",
    "# # Remover linhas que s√£o inteiramente duplicadas (usando o subset seguro definido na inspe√ß√£o)\n",
    "# df_analise.drop_duplicates(subset=colunas_para_verificar, inplace=True)\n",
    "\n",
    "# --- 4.6 Cria√ß√£o de Novas Colunas (Engenharia de Features) ---\n",
    "# # Extrair informa√ß√µes de datas\n",
    "# df_analise['ano_venda'] = df_analise['data_venda'].dt.year\n",
    "# df_analise['mes_venda'] = df_analise['data_venda'].dt.month\n",
    "\n",
    "# # Criar categorias a partir de uma vari√°vel num√©rica (Binning)\n",
    "# df_analise['faixa_etaria'] = pd.cut(df_analise['idade'], bins=[0, 18, 35, 60, 100], labels=['Jovem', 'Adulto', 'Meia-Idade', 'Idoso'])\n",
    "\n",
    "# --- 4.7 Limpeza e Padroniza√ß√£o de Strings ---\n",
    "# # Remover espa√ßos em branco no in√≠cio e no fim de uma coluna de texto\n",
    "# df_analise['nome_produto'] = df_analise['nome_produto'].str.strip()\n",
    "\n",
    "# # Padronizar para letras min√∫sculas\n",
    "# df_analise['cidade'] = df_analise['cidade'].str.lower()\n",
    "\n",
    "print(\"Etapa de limpeza e pr√©-processamento conclu√≠da. Verifique os resultados abaixo.\")\n",
    "# df_analise.info() # √â uma boa pr√°tica verificar os tipos de dados novamente ap√≥s a limpeza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transforma√ß√£o e Agrupamento de Dados\n",
    "\n",
    "Ap√≥s a limpeza, podemos come√ßar a transformar os dados, criando agrega√ß√µes e juntando informa√ß√µes de diferentes fontes para responder perguntas de neg√≥cio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.1 Agrupamentos com .groupby() ---\n",
    "# # Objetivo: Calcular estat√≠sticas agregadas para diferentes categorias.\n",
    "# # Exemplo: Calcular o pre√ßo m√©dio, m√≠nimo e m√°ximo por categoria de produto.\n",
    "# df_agrupado_categoria = df_analise.groupby('categoria_produto').agg(\n",
    "#     preco_medio=('preco', 'mean'),\n",
    "#     preco_maximo=('preco', 'max'),\n",
    "#     contagem=('produto', 'count')\n",
    "# ).sort_values(by='preco_medio', ascending=False)\n",
    "# \n",
    "# display(df_agrupado_categoria)\n",
    "\n",
    "# --- 5.2 Tabelas Din√¢micas com .pivot_table() ---\n",
    "# # Objetivo: Reorganizar os dados em formato de matriz, similar a uma tabela din√¢mica do Excel.\n",
    "# # Exemplo: Ver o faturamento total por `ano` e `mes`.\n",
    "# df_pivot = pd.pivot_table(\n",
    "#     df_analise,\n",
    "#     values='faturamento',\n",
    "#     index='ano_venda',\n",
    "#     columns='mes_venda',\n",
    "#     aggfunc='sum',\n",
    "#     fill_value=0 # Preenche meses sem vendas com 0\n",
    "# )\n",
    "# \n",
    "# display(df_pivot)\n",
    "\n",
    "# --- 5.3 Combina√ß√£o de Datasets com .merge() ---\n",
    "# # Objetivo: Enriquecer o dataset principal com informa√ß√µes de outras tabelas.\n",
    "# # Exemplo: Juntar os dados de vendas (df_analise) com um DataFrame de informa√ß√µes de clientes (df_clientes).\n",
    "\n",
    "# # Criando um DataFrame de exemplo para clientes\n",
    "# dados_clientes = {'id_cliente': [101, 102, 103], 'regiao_cliente': ['Sudeste', 'Nordeste', 'Sudeste']}\n",
    "# df_clientes = pd.DataFrame(dados_clientes)\n",
    "\n",
    "# # Juntando os dois DataFrames pela coluna em comum ('id_cliente')\n",
    "# df_completo = pd.merge(\n",
    "#     df_analise, \n",
    "#     df_clientes, \n",
    "#     on='id_cliente', # Chave para a jun√ß√£o\n",
    "#     how='left'      # Mant√©m todos os registros de vendas, mesmo que n√£o encontre cliente correspondente\n",
    "# )\n",
    "# \n",
    "# display(df_completo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exporta√ß√£o dos Dados Tratados\n",
    "\n",
    "Ap√≥s a limpeza e transforma√ß√£o, √© uma excelente pr√°tica salvar o DataFrame resultante. Isso cria um \"checkpoint\" de dados limpos que pode ser usado em outras an√°lises, relat√≥rios ou modelos, sem precisar repetir todo o processo de ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Salvando em CSV (.to_csv) ---\n",
    "# # SUGEST√ÉO: Use ';' como separador e encoding 'utf-8-sig' para m√°xima compatibilidade com Excel.\n",
    "# caminho_saida_csv = 'dados_analise_limpos.csv'\n",
    "# df_analise.to_csv(\n",
    "#     caminho_saida_csv,\n",
    "#     index=False,          # Para n√£o salvar o √≠ndice do DataFrame como uma coluna no arquivo\n",
    "#     sep=';',              # Ponto e v√≠rgula √© bem reconhecido pelo Excel no Brasil\n",
    "#     decimal=',',          # Define a v√≠rgula como separador decimal\n",
    "#     encoding='utf-8-sig'  # 'sig' (Byte Order Mark) ajuda o Excel a reconhecer a codifica√ß√£o UTF-8\n",
    "# )\n",
    "# print(f\"DataFrame limpo salvo em '{caminho_saida_csv}'\")\n",
    "\n",
    "# --- Salvando em Excel (.to_excel) ---\n",
    "# # √ötil para compartilhar com √°reas de neg√≥cio que n√£o usam Python.\n",
    "# caminho_saida_excel = 'dados_analise_limpos.xlsx'\n",
    "# df_analise.to_excel(\n",
    "#     caminho_saida_excel,\n",
    "#     index=False,\n",
    "#     sheet_name='Dados Principais'\n",
    "# )\n",
    "# print(f\"DataFrame limpo salvo em '{caminho_saida_excel}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. An√°lise Explorat√≥ria de Dados (EDA)\n",
    "\n",
    "Com os dados limpos, investigamos e visualizamos os dados para encontrar padr√µes e insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 An√°lise Univariada\n",
    "An√°lise de cada vari√°vel individualmente para entender sua distribui√ß√£o e caracter√≠sticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Para vari√°veis NUM√âRICAS --- \n",
    "# SUGEST√ÉO: Use Histogramas para ver a distribui√ß√£o e Boxplots para identificar outliers.\n",
    "\n",
    "# # Exemplo com uma coluna num√©rica (descomente e adapte)\n",
    "# coluna_numerica = 'sua_coluna_numerica'\n",
    "# sns.histplot(data=df_analise, x=coluna_numerica, kde=True).set_title(f'Distribui√ß√£o de {coluna_numerica}')\n",
    "# plt.show()\n",
    "\n",
    "# sns.boxplot(data=df_analise, x=coluna_numerica).set_title(f'Boxplot de {coluna_numerica}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Para vari√°veis CATEG√ìRICAS ---\n",
    "# SUGEST√ÉO: Use Gr√°ficos de Barras para ver a frequ√™ncia de cada categoria.\n",
    "\n",
    "# # Exemplo com uma coluna categ√≥rica (descomente e adapte)\n",
    "# coluna_categorica = 'sua_coluna_categorica'\n",
    "# sns.countplot(data=df_analise, y=coluna_categorica, order = df_analise[coluna_categorica].value_counts().index).set_title(f'Contagem de {coluna_categorica}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 An√°lise Bivariada\n",
    "An√°lise da rela√ß√£o entre pares de vari√°veis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Rela√ß√£o entre duas vari√°veis NUM√âRICAS ---\n",
    "# SUGEST√ÉO: Use Gr√°fico de Dispers√£o (Scatter Plot) para identificar correla√ß√µes.\n",
    "\n",
    "# # Exemplo (descomente e adapte)\n",
    "# sns.scatterplot(data=df_analise, x='coluna_numerica_X', y='coluna_numerica_Y').set_title('Rela√ß√£o entre X e Y')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Rela√ß√£o entre uma vari√°vel NUM√âRICA e uma CATEG√ìRICA ---\n",
    "# SUGEST√ÉO: Use Boxplots ou Violin Plots para comparar a distribui√ß√£o da vari√°vel num√©rica entre as categorias.\n",
    "\n",
    "# # Exemplo (descomente e adapte)\n",
    "# sns.boxplot(data=df_analise, x='coluna_categorica', y='coluna_numerica').set_title('Distribui√ß√£o Num√©rica por Categoria')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Rela√ß√£o entre duas vari√°veis CATEG√ìRICAS ---\n",
    "# SUGEST√ÉO: Use uma Tabela de Conting√™ncia (crosstab) e um Mapa de Calor (Heatmap) para visualizar a rela√ß√£o.\n",
    "\n",
    "# # Exemplo (descomente e adapte)\n",
    "# contingency_table = pd.crosstab(df_analise['coluna_categorica_1'], df_analise['coluna_categorica_2'])\n",
    "# sns.heatmap(contingency_table, annot=True, fmt='d', cmap='YlGnBu')\n",
    "# plt.title('Mapa de Calor da Rela√ß√£o entre Categoria 1 e 2')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclus√µes e Pr√≥ximos Passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Escreva aqui os principais insights e pr√≥ximos passos da an√°lise.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exporta√ß√£o do Script\n",
    "\n",
    "Convertemos este notebook em um script Python limpo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certifique-se de que o nome do arquivo corresponde ao seu notebook\n",
    "converter_notebook_para_py('notebook_modelo.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
